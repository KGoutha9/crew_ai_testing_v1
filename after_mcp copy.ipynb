{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b034c8",
   "metadata": {},
   "source": [
    "# Employee Information Retrieval using MCP\n",
    "\n",
    "This notebook demonstrates how to use the Model Context Protocol (MCP) to retrieve employee information from a dedicated server. We'll connect to an Employee Information tool server and use a language model to query employee data.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Azure OpenAI Integration**: Using Azure's OpenAI service to power our agent\n",
    "2. **MCP Client Setup**: Connecting to the Employee Information tool server\n",
    "3. **Agent Creation**: Building a ReAct agent that can use the MCP tools\n",
    "4. **Query Execution**: Retrieving specific employee information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae5edd",
   "metadata": {},
   "source": [
    "## Required Library Imports\n",
    "\n",
    "The following cell imports all necessary libraries for working with MCP, Azure OpenAI, and LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import random\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "import time\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71583031",
   "metadata": {},
   "source": [
    "## Azure OpenAI Configuration\n",
    "\n",
    "Setting up the Azure OpenAI client with appropriate API credentials and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_API_VERSION = \"2024-10-21\"\n",
    "AZURE_ENDPOINT = \"Azure_End_Point\"\n",
    "AZURE_API_KEY = \"<Azure_API_KEy>\"\n",
    "\n",
    "def llm():\n",
    "    model = AzureChatOpenAI(\n",
    "        api_version= AZURE_API_VERSION,\n",
    "        azure_endpoint= AZURE_ENDPOINT,\n",
    "        api_key= AZURE_API_KEY,\n",
    "        azure_deployment=\"gpt-4o\",\n",
    "        verbose=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "azure_api_client = llm()\n",
    "# Setting up the Azure OpenAI model\n",
    "# Note: In a production environment, store these keys securely, not directly in code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873fc1a5",
   "metadata": {},
   "source": [
    "## Connecting to the Employee Information MCP Server\n",
    "\n",
    "In this section, we establish a connection to the Employee Information tool server using the MCP client. This server provides tools that can retrieve employee data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the Employee Information server using MCP\n",
    "# The server should be running on localhost:8001 with SSE transport\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"Employee_Info_tool_server\": {\n",
    "            \"url\": \"http://localhost:8001/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    tools = client.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138d876",
   "metadata": {},
   "source": [
    "## Displaying Available Tools\n",
    "\n",
    "Let's examine the available tools provided by the Employee Information server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9212b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_employee_supervisor', description=\"\\n    Returns the supervisor for a given employee ID.\\n\\n    Args:\\n        employee_ID (str): The unique identifier of an employee.\\n\\n    Returns:\\n        str: Supervisor's name associated with the given employee ID.\\n    \", args_schema={'properties': {'employee_ID': {'title': 'Employee Id', 'type': 'string'}}, 'required': ['employee_ID'], 'title': 'get_employee_supervisorArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121f05300>),\n",
       " StructuredTool(name='get_employee_location', description='\\n    Returns the location of a given employee.\\n\\n    Args:\\n        employee_name (str): The name of the employee.\\n\\n    Returns:\\n        str: Location where the employee is based.\\n    ', args_schema={'properties': {'employee_name': {'title': 'Employee Name', 'type': 'string'}}, 'required': ['employee_name'], 'title': 'get_employee_locationArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121f05b20>),\n",
       " StructuredTool(name='get_employee_ID', description='\\n    Returns the employee ID for a given employee name.\\n\\n    Args:\\n        employee_name (str): The name of the employee.\\n\\n    Returns:\\n        str: Unique ID assigned to the employee.\\n    ', args_schema={'properties': {'employee_name': {'title': 'Employee Name', 'type': 'string'}}, 'required': ['employee_name'], 'title': 'get_employee_IDArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121f058a0>),\n",
       " StructuredTool(name='get_employee_skill_set', description='\\n    Returns the skill set of a given employee ID.\\n\\n    Args:\\n        employee_ID (str): The unique identifier of the employee.\\n\\n    Returns:\\n        str: Primary skill associated with the employee.\\n    ', args_schema={'properties': {'employee_ID': {'title': 'Employee Id', 'type': 'string'}}, 'required': ['employee_ID'], 'title': 'get_employee_skill_setArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121f05a80>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a0fec",
   "metadata": {},
   "source": [
    "## Creating an Agent and Querying Employee Information\n",
    "\n",
    "Now we'll create a ReAct agent that uses the Azure OpenAI model and the MCP tools to query information about an employee named David."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fccd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"Employee_Info_tool_server\": {\n",
    "            \"url\": \"http://localhost:8001/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    agent = create_react_agent(azure_api_client, client.get_tools())\n",
    "    response = await agent.ainvoke({\"messages\": \"what is the location of David\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434211e",
   "metadata": {},
   "source": [
    "## Agent Response\n",
    "\n",
    "Examining the response from our agent after it has queried the employee information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a12632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the location of David', additional_kwargs={}, response_metadata={}, id='f29295bc-23c9-4f97-853b-288105230b39'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_E8rEoI2NdcfyCxO6EYA9QQvz', 'function': {'arguments': '{\"employee_name\":\"David\"}', 'name': 'get_employee_location'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 233, 'total_tokens': 250, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BicbJhxIKnhv4OR6IDwBbOtqPspjs', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-617ffc87-bdb2-4d1b-bd8b-a2214b5a5492-0', tool_calls=[{'name': 'get_employee_location', 'args': {'employee_name': 'David'}, 'id': 'call_E8rEoI2NdcfyCxO6EYA9QQvz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 233, 'output_tokens': 17, 'total_tokens': 250, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='The location for David is Hyderbad', name='get_employee_location', id='46f3a5cc-6497-40af-84d5-f680e11dea47', tool_call_id='call_E8rEoI2NdcfyCxO6EYA9QQvz'),\n",
       "  AIMessage(content='David is based in Hyderabad.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 266, 'total_tokens': 274, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BicbKai3p3L7c7xZ0r5vKSJa3uNPx', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-29b4ffaa-d0ff-4140-a3dc-6dc8cbe9e1a3-0', usage_metadata={'input_tokens': 266, 'output_tokens': 8, 'total_tokens': 274, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22ebfd",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Let's try a few more queries to test the capabilities of our employee information system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of querying information about another employee\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"Employee_Info_tool_server\": {\n",
    "            \"url\": \"http://localhost:8001/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    agent = create_react_agent(azure_api_client, client.get_tools())\n",
    "    # You can modify this query to ask different questions\n",
    "    response = await agent.ainvoke({\"messages\": \"What is the department of Sarah?\"})\n",
    "    \n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f13d6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Model Context Protocol (MCP) to create an agent that can interact with an Employee Information tool server. This architecture allows for:\n",
    "\n",
    "1. **Modular Tool Development**: The employee information tools can be developed and maintained separately from the agent\n",
    "2. **Scalability**: Additional tool servers can be easily connected to the same agent\n",
    "3. **Flexibility**: The agent can dynamically use the tools provided by the server without needing to be reconfigured\n",
    "\n",
    "This approach is particularly powerful for building enterprise applications where different teams might maintain different services and data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7353a2",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [LangChain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)\n",
    "2. [Model Context Protocol - Tools](https://modelcontextprotocol.io/docs/concepts/tools)\n",
    "3. [LangGraph MCP Agents Hands-On](https://github.com/teddynote-lab/langgraph-mcp-agents/blob/master/MCP-HandsOn-ENG.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
