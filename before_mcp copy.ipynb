{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2586778a",
   "metadata": {},
   "source": [
    "# Employee Information System - Before MCP Implementation\n",
    "\n",
    "This notebook demonstrates a traditional approach to creating an agent that handles employee information queries before implementing the Model Context Protocol (MCP). We'll create custom tools directly within the notebook and use them with a language model to answer questions about employees.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Azure OpenAI Integration**: Using Azure's OpenAI service to power our agent\n",
    "2. **Custom Tool Definitions**: Creating tools for employee information retrieval directly in the notebook\n",
    "3. **Agent Creation**: Building a ReAct agent with the defined tools\n",
    "4. **Query Execution**: Testing the agent with employee information requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6680b7",
   "metadata": {},
   "source": [
    "## Required Library Imports\n",
    "\n",
    "The following cell imports all necessary libraries for working with Azure OpenAI, LangGraph, and creating custom tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9433db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import random\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fa5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_API_VERSION = \"2024-10-21\"\n",
    "AZURE_ENDPOINT = \"Azure_End_Point\"\n",
    "AZURE_API_KEY = \"<Azure_API_KEy>\"\n",
    "\n",
    "def llm():\n",
    "    model = AzureChatOpenAI(\n",
    "        api_version= AZURE_API_VERSION,\n",
    "        azure_endpoint= AZURE_ENDPOINT,\n",
    "        api_key= AZURE_API_KEY,\n",
    "        azure_deployment=\"gpt-4o\",\n",
    "        verbose=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "azure_api_client = llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92ef48",
   "metadata": {},
   "source": [
    "## Azure OpenAI Configuration\n",
    "\n",
    "Setting up the Azure OpenAI client with appropriate API credentials and parameters. This model will serve as the brain of our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f8937",
   "metadata": {},
   "source": [
    "## Custom Tool Definitions\n",
    "\n",
    "In this section, we define several custom tools that our agent will use to retrieve employee information. Each tool is decorated with the `@tool` decorator to make it compatible with the LangChain framework.\n",
    "\n",
    "The tools we're defining include:\n",
    "- **get_employee_supervisor**: Retrieves the supervisor for a given employee ID\n",
    "- **get_employee_location**: Retrieves the location where an employee is based\n",
    "- **get_employee_ID**: Retrieves the employee ID for a given name\n",
    "- **get_employee_skill_set**: Retrieves the primary skill for a given employee ID\n",
    "\n",
    "Note: For demonstration purposes, these tools return random values rather than querying a real database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70861600",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_employee_supervisor(employee_ID: str):\n",
    "    \"\"\"\n",
    "    Returns the supervisor for a given employee ID.\n",
    "\n",
    "    Args:\n",
    "        employee_ID (str): The unique identifier of an employee.\n",
    "\n",
    "    Returns:\n",
    "        str: Supervisor's name associated with the given employee ID.\n",
    "    \"\"\"\n",
    "    list_of_supervisors = ['Michael', 'Jessica', 'David', 'Ashley', 'Christopher']\n",
    "    supervisor = random.choice(list_of_supervisors)\n",
    "    return f\"The supervisor for the given employee is {supervisor}\"\n",
    "\n",
    "@tool\n",
    "def get_employee_location(employee_name: str):\n",
    "    \"\"\"\n",
    "    Returns the location of a given employee.\n",
    "\n",
    "    Args:\n",
    "        employee_name (str): The name of the employee.\n",
    "\n",
    "    Returns:\n",
    "        str: Location where the employee is based.\n",
    "    \"\"\"\n",
    "    list_of_locations = [\"Hyderbad\", \"Bangalore\", \"Chennai\", \"Mumbai\"]\n",
    "    location = random.choice(list_of_locations)\n",
    "    return f\"The location for {employee_name} is {location}\"\n",
    "\n",
    "@tool\n",
    "def get_employee_ID(employee_name: str):\n",
    "    \"\"\"\n",
    "    Returns the employee ID for a given employee name.\n",
    "\n",
    "    Args:\n",
    "        employee_name (str): The name of the employee.\n",
    "\n",
    "    Returns:\n",
    "        str: Unique ID assigned to the employee.\n",
    "    \"\"\"\n",
    "    # Note: This tool has an intentional 30-second delay to simulate a slow database query\n",
    "    # In real applications, this delay might represent a complex database lookup or external API call\n",
    "    print(\"seelping for 30 seconds\")\n",
    "    time.sleep(30)\n",
    "    list_of_ids = ['abd104', '3ni3n', '93jnj', 'ikh2k']\n",
    "    employee_ID = random.choice(list_of_ids)\n",
    "    return employee_ID\n",
    "\n",
    "@tool\n",
    "def get_employee_skill_set(employee_ID: str):\n",
    "    \"\"\"\n",
    "    Returns the skill set of a given employee ID.\n",
    "\n",
    "    Args:\n",
    "        employee_ID (str): The unique identifier of the employee.\n",
    "\n",
    "    Returns:\n",
    "        str: Primary skill associated with the employee.\n",
    "    \"\"\"\n",
    "    skill = random.choice([\"Machine Learning\", \"Generative AI\", \"ML Ops\", \"Image Analysis\"])\n",
    "    return skill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25097fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_prompt = \"\"\"\n",
    "You are an assistant designed to provide employee-related information using the available tools.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc4f51",
   "metadata": {},
   "source": [
    "## Agent System Prompt\n",
    "\n",
    "The system prompt provides context and instructions to the language model about its role. Here, we're defining a simple prompt that tells the model it's an assistant for employee information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526abbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_info_agent = create_react_agent(\n",
    "    model= llm(),  \n",
    "    tools=[get_employee_supervisor, get_employee_location, get_employee_ID,get_employee_skill_set],  \n",
    "    prompt= agent_system_prompt,\n",
    "    checkpointer= InMemorySaver()\n",
    ")\n",
    "# Creating the agent with our custom tools and configuring checkpointing for session persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787cb93",
   "metadata": {},
   "source": [
    "## Creating the Agent\n",
    "\n",
    "Now we'll create a ReAct agent that combines the Azure OpenAI model with our custom tools. This agent will be able to understand natural language queries and decide which tools to use to answer them.\n",
    "\n",
    "We also set up an InMemorySaver for checkpointing, which allows the agent to maintain state between interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7277467",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"what is the location of leo?\"\n",
    "session_id = \"abc_7\"\n",
    "thread_config = {\n",
    "    \"configurable\": {\"thread_id\": session_id}\n",
    "}\n",
    "User_query_prompt = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": user_query}]\n",
    "    }\n",
    "# Setting up a user query and session ID for continuity across interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009f79e",
   "metadata": {},
   "source": [
    "## Executing the Query\n",
    "\n",
    "Finally, we'll invoke the agent with our user query and session configuration. The agent will determine which tools to use and provide a response based on the information it retrieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and return the agent's response\n",
    "# Note: The agent will decide which tools to use based on the query\n",
    "employee_info_agent.invoke(User_query_prompt,config= thread_config )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c4671",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "You can modify the user query in the cell above to ask different questions about employees. For example:\n",
    "\n",
    "- \"Who is the supervisor for employee with ID abd104?\"\n",
    "- \"What are the skills of the employee with ID 3ni3n?\"\n",
    "- \"Get me the employee ID for Jessica\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a78b39",
   "metadata": {},
   "source": [
    "## Limitations of This Approach\n",
    "\n",
    "This approach has several limitations compared to the MCP implementation:\n",
    "\n",
    "1. **Tight Coupling**: Tools are directly defined in the notebook, making them difficult to maintain or update independently\n",
    "2. **Limited Scalability**: Adding new tools requires modifying this notebook and restarting the agent\n",
    "3. **No Service Architecture**: Tools can't easily be deployed as separate services or shared across different agents\n",
    "4. **Performance Issues**: As seen with the intentional delay in `get_employee_ID`, performance issues in one tool affect the entire system\n",
    "\n",
    "In the MCP implementation, these limitations are addressed by separating tools into dedicated services that can be independently deployed, scaled, and maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298a667",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to create a basic employee information system using custom tools defined directly within the notebook. While this approach works for simple cases, it has significant limitations in terms of scalability, maintainability, and performance isolation.\n",
    "\n",
    "The next step is to refactor this system using the Model Context Protocol (MCP), which will allow us to separate the tools into dedicated services that can be independently deployed and maintained. This approach is demonstrated in the `after_mcp.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457bcd7",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [LangChain Tool Decorators](https://python.langchain.com/docs/modules/agents/tools/custom_tools)\n",
    "2. [LangGraph ReAct Agents](https://python.langchain.com/docs/templates/react)\n",
    "3. [Model Context Protocol Documentation](https://modelcontextprotocol.io/docs/concepts/tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
